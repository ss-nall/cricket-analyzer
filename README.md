# ğŸ Cricket Analyzer

A deep learning + computer vision based **cricket shot analyzer**.  
This project extracts pose keypoints from batting videos using **MediaPipe**, trains a **Temporal Convolutional Network (TCN)** to learn motion patterns, and then compares user-uploaded shots against reference "perfect" shots using **Dynamic Time Warping (DTW)**.  

A **Streamlit app** is included to visualize and interact with the system.

---

## ğŸš€ Features
- Pose keypoint extraction from cricket videos using **MediaPipe Holistic**.
- Sequence alignment and comparison with **DTW**.
- Trainable **Conv1D / TCN models** for sequence learning.
- Side-by-side video display of user vs reference shot.
- Score + suggestions generated automatically.
- Clean Streamlit interface with futuristic UI.

---

## ğŸ“‚ Project Structure
cricket_analyzer_project/
â”‚
â”œâ”€â”€ data/ # (ignored) raw + reference videos, extracted npz
â”‚ â”œâ”€â”€ perfect_shots/ # reference shots (e.g., cover_drive.mp4)
â”‚ â””â”€â”€ raw_videos/ # user input videos
â”‚
â”œâ”€â”€ models/ # (ignored) trained models (h5/keras)
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ app.py # Streamlit app
â”‚ â”œâ”€â”€ analysis.py # DTW + feedback logic
â”‚ â”œâ”€â”€ pose_extraction.py # keypoint extraction
â”‚ â”œâ”€â”€ model_training.py # training pipeline
â”‚ â””â”€â”€ utils/ # helper functions
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ .gitignore


> **Note:** `data/` and `models/` are git-ignored to avoid pushing large files.  
> Store videos/models externally (Google Drive, S3, etc.) and document their paths.

---

## ğŸ› ï¸ Setup & Installation

### 1. Clone the repository
```bash
git clone https://github.com/<USER>/<REPO>.git
cd <REPO>
2. Create and activate a virtual environment
python -m venv venv
# On Windows
.\venv\Scripts\activate
# On Mac/Linux
source venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

4. Prepare your videos

Organize data like this:

data/
 â”œâ”€â”€ perfect_shots/
 â”‚    â”œâ”€â”€ cover_drive.mp4
 â”‚    â”œâ”€â”€ pull_shot.mp4
 â”‚    â””â”€â”€ ...
 â””â”€â”€ raw_videos/
      â”œâ”€â”€ cover_drive/
      â”‚    â””â”€â”€ user1.mp4
      â””â”€â”€ pull_shot/
           â””â”€â”€ user2.mp4

ğŸ‹ï¸ Workflow
Step 1 â€” Extract keypoints
python src/pose_extraction.py


This creates .npz keypoint files in data/.

Step 2 â€” Train model
python src/model_training.py


This trains a simple Conv1D/TCN model and saves it in models/.

Step 3 â€” Run the app
streamlit run src/app.py


Upload your batting video and choose a reference shot.
The app will:

Show side-by-side videos (your shot vs reference).

Display similarity score.

Suggest improvements based on joint alignment.

ğŸ“Š Example Output

Similarity Score: 78%

Suggestions:

Backlift angle slightly off.

Footwork slower than reference.

Follow-through is consistent.

âš ï¸ Notes

Donâ€™t push heavy .mp4 or .h5 files to GitHub directly.

Use Git LFS
 or external storage.

Adjust hyperparameters in model_training.py for better accuracy.

ğŸ§‘â€ğŸ’» Tech Stack

Python 3.10+

MediaPipe

NumPy / Pandas / Scikit-learn

TensorFlow / Keras

Streamlit

ğŸ“Œ Future Work

Improve model accuracy by training with a larger dataset.

Support bowler action analysis.

Add 3D pose estimation for more precise feedback.

Build mobile-friendly version.

ğŸ™Œ Acknowledgements

Google MediaPipe
 for pose estimation.

Dynamic Time Warping
 for sequence alignment.

Inspiration from cricket coaching techniques.
